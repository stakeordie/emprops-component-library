version: '3'

services:
  # API Container - Frontend HTTP API
  api:
    build:
      context: ..
      dockerfile: ./mock-env/api/Dockerfile
    ports:
      - "8000:8000"
    environment:
      - REDIS_API_HOST=hub
      - REDIS_API_PORT=8001
      - REDIS_HOST=hub  # For Redis DB direct connections
      - REDIS_PORT=6379 # Redis standard port
      - LOG_LEVEL=DEBUG # Critical for seeing detailed logs
    networks:
      - redis-network
    depends_on:
      - hub
    volumes:
      - ./api:/app
    command: |
      bash -c '
      # Debug directory contents
      echo "API Container directory contents:" 
      ls -la /app
      echo "/app/core contents:"
      ls -la /app/core
      echo "Python path:" 
      python -c "import sys; print(sys.path)"
      
      # Start the API service (directly from mounted /app)
      echo "RUNNING FROM DIRECTLY MOUNTED CODE IN /app" 
      uvicorn main:app --host 0.0.0.0 --port 8000 --reload
      '

  # Hub Container - Redis API + Redis DB
  hub:
    build:
      context: ..
      dockerfile: ./mock-env/hub/Dockerfile
    ports:
      - "8001:8001"  # Redis API
      - "6380:6379"  # Redis DB (mapped to different host port)
    networks:
      - redis-network
    volumes:
      - ./hub:/app/hub-updates
    command: |
      bash -c '
      # Start Redis - binding to all interfaces for container networking
      redis-server --daemonize yes --bind 0.0.0.0
      
      # Debug directory contents
      echo "HUB Container directory contents:" 
      ls -la /app
      echo "/app/core contents:"
      ls -la /app/core
      echo "Python path:" 
      python -c "import sys; print(sys.path)"
      
      # Start the Hub API service
      uvicorn main:app --host 0.0.0.0 --port 8001 --reload
      '

  # GPU Containers - SIMPLIFIED FOR TESTING (single worker only)
  gpu1:
    build:
      context: ..
      dockerfile: ./mock-env/gpu/Dockerfile
    environment:
      - MACHINE_ID=1
      - GPU_ID=1
      - NUM_WORKERS=1
      - REDIS_API_HOST=hub
      - REDIS_API_PORT=8001
      - EXECUTION_SERVICE_PORT=9001
    ports:
      - "9001:9001"  # Execution Service
    networks:
      - redis-network
    depends_on:
      - hub
    volumes:
      - ./gpu:/app/gpu-updates
      - ./gpu/worker.py:/app/worker.py
    # Direct command instead of using start.sh
    command: |
      bash -c '
      # Debug directory contents
      echo "Container directory contents:" 
      ls -la /app
      echo "/app/core contents:"
      ls -la /app/core

      # Start execution service
      echo "Starting execution service on port $$EXECUTION_SERVICE_PORT..."
      python /app/execution_service.py &
      
      # Start workers based on NUM_WORKERS environment variable
      echo "Starting $$NUM_WORKERS workers..."
      for ((i=1; i<=$$NUM_WORKERS; i++))
      do
        echo "Starting worker $$i..."
        python /app/worker.py --worker-id "$$MACHINE_ID-worker-$$i" &
      done
      
      # Keep container running
      tail -f /dev/null
      '

  # gpu2 - DISABLED FOR TESTING
  # gpu2:
  #   build:
  #     context: ..
  #     dockerfile: ./mock-env/gpu/Dockerfile
  #   environment:
  #     - MACHINE_ID=gpu2
  #     - NUM_WORKERS=4
  #     - REDIS_API_HOST=hub
  #     - REDIS_API_PORT=8001
  #     - EXECUTION_SERVICE_PORT=9002
  #   ports:
  #     - "9002:9002"  # Execution Service
  #   networks:
  #     - redis-network
  #   depends_on:
  #     - hub
  #   volumes:
  #     - ./gpu:/app/gpu-updates
  #   # Direct command instead of using start.sh
  #   command: |
  #     bash -c '
  #     # Debug directory contents
  #     echo "Container directory contents:" 
  #     ls -la /app
  #     echo "/app/core contents:"
  #     ls -la /app/core

  #     # Start execution service
  #     echo "Starting execution service on port $$EXECUTION_SERVICE_PORT..."
  #     python /app/execution_service.py &
  #     
  #     # Start workers based on NUM_WORKERS environment variable
  #     echo "Starting $$NUM_WORKERS workers..."
  #     for ((i=1; i<=$$NUM_WORKERS; i++))
  #     do
  #       echo "Starting worker $$i..."
  #       python /app/worker.py --worker-id "$$MACHINE_ID-worker-$$i" &
  #     done
  #     
  #     # Keep container running
  #     tail -f /dev/null
  #     '

  # gpu3 - DISABLED FOR TESTING
  # gpu3:
  #   build:
  #     context: ..
  #     dockerfile: ./mock-env/gpu/Dockerfile
  #   environment:
  #     - MACHINE_ID=gpu3
  #     - NUM_WORKERS=1
  #     - REDIS_API_HOST=hub
  #     - REDIS_API_PORT=8001
  #     - EXECUTION_SERVICE_PORT=9003
  #   ports:
  #     - "9003:9003"  # Execution Service
  #   networks:
  #     - redis-network
  #   depends_on:
  #     - hub
  #   volumes:
  #     - ./gpu:/app/gpu-updates
  #   # Direct command instead of using start.sh
  #   command: |
  #     bash -c '
  #     # Debug directory contents
  #     echo "Container directory contents:" 
  #     ls -la /app
  #     echo "/app/core contents:"
  #     ls -la /app/core

  #     # Start execution service
  #     echo "Starting execution service on port $$EXECUTION_SERVICE_PORT..."
  #     python /app/execution_service.py &
  #     
  #     # Start workers based on NUM_WORKERS environment variable
  #     echo "Starting $$NUM_WORKERS workers..."
  #     for ((i=1; i<=$$NUM_WORKERS; i++))
  #     do
  #       echo "Starting worker $$i..."
  #       python /app/worker.py --worker-id "$$MACHINE_ID-worker-$$i" &
  #     done
  #     
  #     # Keep container running
  #     tail -f /dev/null
  #     '

  # gpu4 - DISABLED FOR TESTING
  # gpu4:
  #   build:
  #     context: ..
  #     dockerfile: ./mock-env/gpu/Dockerfile
  #   environment:
  #     - MACHINE_ID=gpu4
  #     - NUM_WORKERS=1
  #     - REDIS_API_HOST=hub
  #     - REDIS_API_PORT=8001
  #     - EXECUTION_SERVICE_PORT=9004
  #   ports:
  #     - "9004:9004"  # Execution Service
  #   networks:
  #     - redis-network
  #   depends_on:
  #     - hub
  #   volumes:
  #     - ./gpu:/app/gpu-updates
  #   # Direct command instead of using start.sh
  #   command: |
  #     bash -c '
  #     # Debug directory contents
  #     echo "Container directory contents:" 
  #     ls -la /app
  #     echo "/app/core contents:"
  #     ls -la /app/core

  #     # Start execution service
  #     echo "Starting execution service on port $$EXECUTION_SERVICE_PORT..."
  #     python /app/execution_service.py &
  #     
  #     # Start workers based on NUM_WORKERS environment variable
  #     echo "Starting $$NUM_WORKERS workers..."
  #     for ((i=1; i<=$$NUM_WORKERS; i++))
  #     do
  #       echo "Starting worker $$i..."
  #       python /app/worker.py --worker-id "$$MACHINE_ID-worker-$$i" &
  #     done
  #     
  #     # Keep container running
  #     tail -f /dev/null
  #     '

  # gpu5 - DISABLED FOR TESTING
  # gpu5:
  #   build:
  #     context: ..
  #     dockerfile: ./mock-env/gpu/Dockerfile
  #   environment:
  #     - MACHINE_ID=gpu5
  #     - NUM_WORKERS=2
  #     - REDIS_API_HOST=hub
  #     - REDIS_API_PORT=8001
  #     - EXECUTION_SERVICE_PORT=9005
  #   ports:
  #     - "9005:9005"  # Execution Service
  #   networks:
  #     - redis-network
  #   depends_on:
  #     - hub
  #   volumes:
  #     - ./gpu:/app/gpu-updates
  #   # Direct command instead of using start.sh
  #   command: |
  #     bash -c '
  #     # Debug directory contents
  #     echo "Container directory contents:" 
  #     ls -la /app
  #     echo "/app/core contents:"
  #     ls -la /app/core

  #     # Start execution service
  #     echo "Starting execution service on port $$EXECUTION_SERVICE_PORT..."
  #     python /app/execution_service.py &
  #     
  #     # Start workers based on NUM_WORKERS environment variable
  #     echo "Starting $$NUM_WORKERS workers..."
  #     for ((i=1; i<=$$NUM_WORKERS; i++))
  #     do
  #       echo "Starting worker $$i..."
  #       python /app/worker.py --worker-id "$$MACHINE_ID-worker-$$i" &
  #     done
  #     
  #     # Keep container running
  #     tail -f /dev/null
  #     '

networks:
  redis-network:
    driver: bridge
